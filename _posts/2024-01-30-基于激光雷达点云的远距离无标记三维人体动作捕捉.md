---
layout: post
title: 《基于激光雷达点云的远距离无标记三维人体动作捕捉》笔记
subtitle: 
categories: 科研笔记
tags: [文献, LiDAR, 人体动作捕捉]
---

这篇论文看了一个月了，3.1 才看完 = = 

## 名词解释

- **多模态**：多种模态/形式（的人体的观测数据）

相较单模态（例如图片、文字）能表达更丰富的信息

- **三维人体动作捕捉**：整合传感器对人体的观测结果，恢复出真实的人体动作

## Abstract

提出**基于 LiDAR(Light Detection and Ranging) 激光雷达** 的数据集 & 人体动作捕捉框架

> LiDAR: 激光探测与测距（设备）

### 创新点

1. 提出多模态数据集： 
RGB + LiDAR + IMU(传感器，可测量运动，受磁场影响)
2. 提出无标记、远距离人体动作捕捉框架

### 动作捕捉

将人体或者其他物体的动作以数字化的方式进行记录和存储

具体来说是输出一些表示 shape 和 pose 的参数，加到参数化模型上得到真实人体动作

### LiDAR

LiDAR作用：采集点云（深度数据）

## Related Work

### 动捕

#### 数据集

（有真实的三维动作的：）

Human3.6M、HumanEva、MPI-INF-3DHP：室内 & 基于标记

3DPW：室外 & 基于标记 & SMPL

#### 动捕方法

1.**基于标记**：人体穿戴标记，采集动作

分为 被动光学动捕（穿戴反光设备，再由摄像机捕捉）、主动光学动捕（穿戴发射光源的设备）、惯性动捕方法（穿戴IMU记录动作数据）

缺点：

- 成本高昂、复杂

- 影响动作真实性

2.**无标记**：仅由传感器的观测和算法分析推导出人体的运动情况

例如 HMR(使用SMPL模型)、VIBE(输入是RGB视频)

缺点：远距离导致图像质量退化

### LiDAR 激光雷达

#### 目标追踪任务

指给你一个物体的图像，需要在视频里追踪这个目标物体

方法一：使用滤波器生成下一时刻的物体位置，但是存在被遮挡的问题

方法二：输入相邻的两帧点云，算法能追踪到物体的变化

#### 场景流任务

描述了源点云中的每个点到目标点云中对应点的位移，即动态环境中点的三维运动信息。

#### 三维点云深度特征学习

- 静态

点云分类、分割

- 动态

追踪点云

## 多模态人体动作捕捉标准数据集制备

### 采集系统

时间同步：同步 LiDAR、动作捕捉系统和相机的时钟源，使用 PTP (Precision Time Protocol) 协议。

### 数据预处理

- 点云预处理：去除人体以外的背景噪声干扰

- 图像预处理：运用一些变化矩阵使点云和图像对齐

- IMU 预处理：参数化模型；使点云与 LiDAR 采集的点云对齐

### 标准数据集描述

多模态数据集包括 LiDAR，RGB 视频以及由 IMU 动作捕捉系统提供的真实三维人体动作

提供了 **深度信息**

## 基于点云的三维人体动作捕捉框架

### 动态点云编码

因为收集到的数据形式是点云，需要将点云转换成高维的 vector 作为神经网络的输入

- PointNet

输入是点云，输出是表征这个点云的特征的 1024-dim vector

- PointNet++

输入输出同 PointNet，不同之处在于网络结构

### 算法

引入了 SMPL 模型，从点云编码先回归出关节位置，后回归出关节的旋转角度（。。。

深度学习网络的**输入**是**动态点云编码的高维 vector**，**输出**是**人体模型参数(SMPL)**。可以依据这个输出恢复出真实的三维人体

## 对比与评估

与基于图像的方法对比.....???，评价指标上更好

## Ques

- LiDAR 属于无标记？ 

有标记只有光学 & IMU，无标记包含了“传感器观测”

- LiDAR 收集到的数据是什么形式的？

点云

- 时间同步具体是怎么做的？

？
