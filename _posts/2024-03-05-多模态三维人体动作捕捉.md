---
layout: post
title: 多模态三维人体动作捕捉
subtitle: 流程
categories: 科研实验
tags: [pytorch, 环境]
---
- 跑通了代码

- 理了理人体动捕大致实验流程

- 尝试了几种可视化工具

## Train

loss 是人体 3D 关节点的位置和旋转矩阵一起计算的

代码路径 `../forder1/lidarcap_1/train.py`，需要在配置文件里修改 data 的路径dddd

训练 250 个 epochs 大概需要 14 h

训练(with 验证集)完后得到了 model 的参数，在 `debuged_model` 文件夹里

## Test

代码路径 `../forder1/lidarcap_1/eval.py`

测试非常快，可能只有10+s

输出是一组 SMPL 模型的 poses 参数（也有 joints 位置）

## 可视化⭐

得到了 SMPL 模型的参数 poses，自然而然想去可视化出来

服务器本身没有显示器，是无法可视化的

很多用的是在本地做可视化（也有一些其他方法。。。

### easy ver

学长写的 open3d_server，修改**测试集数据路径**和 **SMPL 参数(轴角式旋转)**运行在本地，但是无法做到和视频中的人体对齐（因为代码本身只有 poses 数据是必要的，没有图片和相机的参数）

### aitviewer

项目在本地 `F:\py_files_aitviewer` 运行。

是一个能同时展示 SMPL模型 和 对齐的RGB图像 可视化工具。

使用方法是在 `examples/load_xxx.py` 文件中，加载特定格式下的**数据集（例如 3DPW, AMASS 等）**，还需要加载每一帧对应的**RGB图像**和**相机位姿参数**

#### 官方demo

跑通了 aitviewer 中 load_3DPW.py 使用 **3DPW** 数据集的代码，有人物 SMPL 模型在视频中的可视化结果

#### 3DPW Dataset

The 3DPW dataset contains several motion sequences, which are organized into two folders: imageFiles and sequenceFiles.
The folder imageFiles contains the RGB-images for every sequence. 
The folder sequenceFiles provides synchronized motion data and SMPL model parameters in the form of .pkl-files. For each sequence, the .pkl-file contains a dictionary with the following fields:
- sequence: String containing the sequence name，视频的名字
- betas: SMPL shape parameters for each actor which has been used for tracking (List of 10x1 SMPL beta parameters)，表示 shape 的数据
- poses: SMPL body poses for each actor aligned with image data (List of Nx72 SMPL joint angles, N = #frames)，表示 pose 的数据
- trans: tranlations for each actor aligned with image data (List of Nx3 root translations)，施加这个变换才是修正后的人体
- poses_60Hz: SMPL body poses for each actor at 60Hz (List of Nx72 SMPL joint angles, N = #frames)
- trans_60Hz: tranlations for each actor at 60Hz (List of Nx3 root translations)
- betas_clothed: SMPL shape parameters for each clothed actor (List of 10x1 SMPL beta parameters)
- v_template_clothed: 
- gender: actor genders (List of strings, either 'm' or 'f')
- texture_maps: texture maps for each actor
- poses2D: 2D joint detections in Coco-Format for each actor (only provided if at least 6 joints were detected correctly)
- jointPositions: 3D joint positions of each actor (List of Nx(24*3) XYZ coordinates of each SMPL joint)，3D 关节点的位置
- img_frame_ids: an index-array to down-sample 60 Hz 3D poses to corresponding image frame ids，对应图片的帧数的list，eg:[0, 2, 4, ..., 720]
- cam_poses: camera extrinsics for each image frame (Ix4x4 array, I frames times 4x4 homegenous rigid body motion matrices)，相机外参，每一帧视频对应一组外参
- campose_valid: a boolean index array indicating which camera pose has been aligned to the image，每一帧相机外参是否有效，有效是 1
- cam_intrinsics: camera intrinsics (K = [f_x 0 c_x;0 f_y c_y; 0 0 1])，相机内参

Each sequence has either one or two models, which corresponds to the list size of the model specific fields (e.g. betas, poses, trans, v_template, gender, texture_maps, jointPositions, poses2D). 
SMPL poses and translations are provided at 30 Hz. They are aligned to image dependent data (e.g. 2D poses, camera poses). In addition we provide 'poses_60Hz' and 'trans_60Hz' which corresponds to the recording frequency of 60Hz of the IMUs . You could use the 'img_frame_ids' to downsample and align 60Hz 3D and image dependent data, wich has been done to compute SMPL 'poses' and 'trans' variables. 
Please refer to the demo.py-file for loading a sequence, setup smpl-Models and camera, and to visualize an example frame.

#### 制作数据集

制作 3DPW 格式的数据集，需要 16 个数据项，其中有的参数是不太好获取的，例如 `poses2d`，是以 COCO-DATASET 的格式存储 2D 关节点的坐标。（所以这是一个非常耗时的过程）

在[原论文](http://www.lidarhumanmotion.net/lidarcap/)中，作者只提供了一组相机外参(1x4x4)，不是每一帧都有，因此无法根据这个制作成 3DPW 格式数据集（或许需要使用多视角图像 + COLMAP 来算出相机位姿）

我只好令每一帧视频的相机外参都为相同的这个值，结果可视化之后完全看不见数字人

重新看了看原文，作者可视化出来的人物也是没有和背景对齐的，甚至只用了 SMPL-X 模型 

### SMPL-Viewer

https://github.com/climbingdaily/SMPL-Scene-Viewer

注意 bcrypt==4.0.1, open3d==0.15.1

可以导入 pkl, obj 文件

### SMPL

对于每组 {shape, pose} 参数，能生成一个人体SMPL obj 文件

不能和背景人体图像对齐

尚不清楚如何处理视频

### SMPL-X

官方demo能跑，但是会卡在 mesh 生成的阶段